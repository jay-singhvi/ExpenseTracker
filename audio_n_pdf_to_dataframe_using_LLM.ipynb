{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tabula\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv(dotenv_path=\"./../../.env\", override=True)\n",
    "\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Specify the project root directory\n",
    "root_dir = os.getcwd()\n",
    "\n",
    "# Define the path to the ffmpeg bin directory\n",
    "ffmpeg_bin_path = root_dir + r\"\\ffmpeg-n6.1-latest-win64-gpl-6.1\\bin\"\n",
    "\n",
    "if ffmpeg_bin_path not in os.environ[\"PATH\"]:\n",
    "    os.environ[\"PATH\"] = ffmpeg_bin_path + \";\" + os.environ[\"PATH\"]\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_response_to_dataframe(model_response: str) -> pd.DataFrame:\n",
    "\n",
    "    # Check if the first line contains column names\n",
    "    has_column_names = any(char.isalpha() for char in model_response.split(\"\\n\")[0])\n",
    "\n",
    "    # Create a StringIO object to simulate a file-like object\n",
    "    transaction_list_string = StringIO(model_response)\n",
    "\n",
    "    # Read CSV into a DataFrame, adjusting the header parameter based on whether column names are present or not\n",
    "    transaction_list_dataframe = pd.read_csv(\n",
    "        transaction_list_string,\n",
    "        sep=\",\",\n",
    "        header=(\n",
    "            0 if has_column_names else None\n",
    "        ),  # Set header to 0 if column names are present, otherwise None\n",
    "        names=(\n",
    "            [\"date\", \"description\", \"amount\"] if not has_column_names else None\n",
    "        ),  # If no column names, provide your own\n",
    "    )\n",
    "\n",
    "    return transaction_list_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_transaction_list(\n",
    "    filepath: str,\n",
    "    pdf_password: str,\n",
    "    client=client,\n",
    "    model=\"gpt-4-1106-preview\",\n",
    ") -> pd.DataFrame:\n",
    "    # Generate the list dynamically\n",
    "    column_list = [\"Column\" + str(i) for i in range(20)]\n",
    "    # print(column_list)\n",
    "    dfs = tabula.read_pdf(\n",
    "        input_path=filepath,\n",
    "        output_format=\"dataframe\",\n",
    "        encoding=\"utf-8\",\n",
    "        password=pdf_password,\n",
    "        pages=\"all\",\n",
    "        multiple_tables=True,\n",
    "        lattice=True,\n",
    "        guess=False,\n",
    "        pandas_options={\n",
    "            \"names\": column_list,\n",
    "            \"header\": None,\n",
    "        },\n",
    "    )\n",
    "    clean_df = pd.DataFrame(columns=column_list)\n",
    "    for i in dfs:\n",
    "        temp_df = (\n",
    "            i.replace(\"\\r\", \" \", regex=True)\n",
    "            .replace(r\"(\\d),(\\d)\", r\"\\1\\2\", regex=True)\n",
    "            .replace(\",\", \" \", regex=True)\n",
    "        )\n",
    "        clean_df = pd.concat([clean_df, temp_df], axis=0, ignore_index=True)\n",
    "    clean_df = clean_df.dropna(axis=1, how=\"all\")\n",
    "    # Convert DataFrame to comma-separated string\n",
    "    csv_string = clean_df.to_csv(index=False)\n",
    "    prompt_str = (\n",
    "        \"\"\"\n",
    "    Using the data provided from a bank statement, transform the transaction details into a standardized list format.\n",
    "    Each transaction entry should be structured as following 3 columns: 'date, description, amount'.\n",
    "    Ensure if the description contains amounts too, then remove it.\n",
    "    Here's the raw data extracted for processing:\n",
    "    \"\"\"\n",
    "        + csv_string\n",
    "        + \"\"\"\n",
    "    Transform this data into a clean, readable list of transactions, adhering to the specified format.\n",
    "    Ensure to include the negative sign for deductions from the account.\n",
    "    Ensure you provide the data nothing else in response\"\"\"\n",
    "    )\n",
    "    # let's verify the function above matches the OpenAI API response\n",
    "    prompt_messgae = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt_str,\n",
    "        },\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model, messages=prompt_messgae, temperature=0  # , max_tokens=1\n",
    "    )\n",
    "\n",
    "    model_response = response.choices[0].message.content\n",
    "    return model_response_to_dataframe(model_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_transaction_list(\n",
    "    file_path, transcription_model=\"whisper-1\", llm_model=\"gpt-4-1106-preview\"\n",
    "):\n",
    "    file_name, file_extension = os.path.splitext(file_path)\n",
    "\n",
    "    audio_file = None\n",
    "    if file_extension != \".mp3\":\n",
    "        AudioSegment.from_file(file_path, format=\"m4a\").export(\n",
    "            f\"{file_name}.mp3\", format=\"mp3\"\n",
    "        )\n",
    "        audio_file = open(f\"{file_name}.mp3\", \"rb\")\n",
    "    else:\n",
    "        audio_file = open(file_path, \"rb\")\n",
    "\n",
    "    transcription = client.audio.transcriptions.create(\n",
    "        model=transcription_model, file=audio_file\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=llm_model,\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"\"\"\n",
    "                    Using the transcription provided from a voice recording, create a list of transaction details into a standardized list format.\n",
    "                    Each transaction entry should be structured as following 3 columns: 'date, description, amount'.\n",
    "                    Here's the raw transcription extracted for processing:\n",
    "                \"\"\"\n",
    "                + transcription.text\n",
    "                + \"\"\"\n",
    "                Transform this data into a clean, readable list of transactions, adhering to the specified format.\n",
    "                Ensure to include the negative sign for deductions from the account.\n",
    "                Ensure you provide the data nothing else in response\"\"\",\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    model_response = response.choices[0].message.content\n",
    "    return model_response_to_dataframe(model_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"Interview 002.m4a\"\n",
    "\n",
    "# Correctly specify the path to your bank statement PDF\n",
    "file_path = root_dir + r\"/data/audio/\" + file_name\n",
    "\n",
    "display(audio_to_transaction_list(file_path))\n",
    "\n",
    "\n",
    "file_name = \"2020 - 02 - February.pdf\"\n",
    "\n",
    "# Correctly specify the path to your bank statement PDF\n",
    "filepath = root_dir + f\"/data/bankstatements/{file_name}\"\n",
    "\n",
    "# Specify the password to decrypt the PDF\n",
    "pdf_password = \"11323650\"\n",
    "\n",
    "display(pdf_to_transaction_list(filepath, pdf_password))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example OpenAI Python library request\n",
    "# MODEL = \"gpt-3.5-turbo\"\n",
    "# response = client.chat.completions.create(\n",
    "#     model=MODEL,\n",
    "#     messages=[\n",
    "#         {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "#         {\"role\": \"user\", \"content\": \"Knock knock.\"},\n",
    "#         {\"role\": \"assistant\", \"content\": \"Who's there?\"},\n",
    "#         {\"role\": \"user\", \"content\": \"Orange.\"},\n",
    "#     ],\n",
    "#     temperature=0,\n",
    "# )\n",
    "# print(json.dumps(json.loads(response.model_dump_json()), indent=4))\n",
    "# response.choices[0].message.content\n",
    "\n",
    "# # example with a system message\n",
    "# response = client.chat.completions.create(\n",
    "#     model=MODEL,\n",
    "#     messages=[\n",
    "#         {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "#         {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": \"Explain asynchronous programming in the style of the pirate Blackbeard.\",\n",
    "#         },\n",
    "#     ],\n",
    "#     temperature=0,\n",
    "# )\n",
    "\n",
    "# print(response.choices[0].message.content)\n",
    "\n",
    "\n",
    "# # example without a system message\n",
    "# response = client.chat.completions.create(\n",
    "#     model=MODEL,\n",
    "#     messages=[\n",
    "#         {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": \"Explain asynchronous programming in the style of the pirate Blackbeard.\",\n",
    "#         },\n",
    "#     ],\n",
    "#     temperature=0,\n",
    "# )\n",
    "\n",
    "# print(response.choices[0].message.content)\n",
    "\n",
    "\n",
    "# # An example of a system message that primes the assistant to explain concepts in great depth\n",
    "# response = client.chat.completions.create(\n",
    "#     model=MODEL,\n",
    "#     messages=[\n",
    "#         {\"role\": \"system\", \"content\": \"You are a friendly and helpful teaching assistant. You explain concepts in great depth using simple terms, and you give examples to help people learn. At the end of each explanation, you ask a question to check for understanding\"},\n",
    "#         {\"role\": \"user\", \"content\": \"Can you explain how fractions work?\"},\n",
    "#     ],\n",
    "#     temperature=0,\n",
    "# )\n",
    "\n",
    "# print(response.choices[0].message.content)\n",
    "\n",
    "\n",
    "# # An example of a system message that primes the assistant to give brief, to-the-point answers\n",
    "# response = client.chat.completions.create(\n",
    "#     model=MODEL,\n",
    "#     messages=[\n",
    "#         {\"role\": \"system\", \"content\": \"You are a laconic assistant. You reply with brief, to-the-point answers with no elaboration.\"},\n",
    "#         {\"role\": \"user\", \"content\": \"Can you explain how fractions work?\"},\n",
    "#     ],\n",
    "#     temperature=0,\n",
    "# )\n",
    "\n",
    "# print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
